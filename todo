- use  find -type f -exec awk -v RS='.' '{IGNORECASE=1;}/nasa/&&/shuttle/{print FILENAME}' {} \;
- fix concep queries
- make chunks dependent on byte size rather than value length 
(and stay under 2gb per file limit)
- eval queries by hand using latest (prec: 67, rec: 66)
- switch back to "old best" (prec: 55, rec: 70)
- try to mix the lastest best and old best, and see if we can improve
- then go forward and using what we have try to prune more aggressively and on a metric like score, or something, to create even more improvements

- get prec and rec between 70 and 80 
- snippets are important to evaluate the document
- multicore indexing (if available), which would be split across a list of documents and merge, complexity from having a shared dictionary, IPC comms?

// old
  - don't pre-emptively optimise, keep the algorithm loose and open before it's thoroughly tested
  - add spanish
  - things we can try to improve performance:
    - the usual parameters, cover, stopping condition, score calculation,1
    - add new things like tf-idf for factors, cosine similarity (on what I don't yet know), boosting doc in (doc, query) based on how many times that doc has been the first clicked result for that query
    - joining documents across factors rather than just summing scores.
    - or summing scores, but multiplying across those factors that share a common document
  - create a way to do snippets (contextual snippets to put the search result in context of the document)
  - create a way to do instant (basically just indexing the queries, and querying those against the current query as it is typed)



